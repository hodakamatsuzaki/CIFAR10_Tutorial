{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5f090ce-9701-4146-9a2b-1d496ec85688",
   "metadata": {},
   "source": [
    "# CIFAR-10データセットを用いて画像分類してみる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9649a70-3872-4d61-816f-6bc70e0c465f",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "021b2c58-2cd7-45db-99a9-bef28b1e156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "sys.path.append('../src')\n",
    "import utils\n",
    "\n",
    "sys.path.append('./src')\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b3328a7-b8e4-4620-afe0-91a11c41789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = utils.readConfig('../config.json')\n",
    "#raw_path = config['filepath']['output_dir'] + '/20211105_log_revise/01'\n",
    "output_path = config['filepath']['output_dir'] + '/01'\n",
    "\n",
    "utils.makeDirs(output_path, ['graph'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ad1603-b2f8-44f0-82ed-18d828b6109c",
   "metadata": {},
   "source": [
    "## GPU or CPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90e63d2-d26f-493f-9636-f1e0781fb9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0a4aea-477f-433f-96d4-93d3cb981c8a",
   "metadata": {},
   "source": [
    "## set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d54d90a-c88f-42a3-9737-9150bdecf0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parserなどで指定\n",
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92dc454-dc85-4dca-bbc4-06eba95eb5df",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d653a6-8973-4b55-9d7e-b7b4abac490d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), #0〜255の整数値を0〜1の浮動小数点数型に変換する\n",
    "    transforms.Normalize((0.5,), (0.5,), (0.5,)) #平均と標準偏差に0.5を指定することで、値の範囲を[-1, 1]にする\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75d4eca-cd6f-4d7a-96ac-81712428e439",
   "metadata": {},
   "source": [
    "##　load datset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "948931d6-1665-4efb-8ebe-59692d98f0cf",
   "metadata": {},
   "source": [
    "CIFAR10の学習用データと検証用データをダウンロードし、それぞれ変数に読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1edd29-45b5-4995-a5b3-e9d48defcd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.CIFAR10(root=\"../output/cifar_data\", train=True, download=True, transform=transform)\n",
    "validation_dataset = datasets.CIFAR10(root=\"../output/cifar_data\", train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7187bee-ae1e-43d9-9814-9b108b3acd94",
   "metadata": {},
   "source": [
    "## dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00815886-82a8-4b16-9eb0-a7959b07a4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader  = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6da8444-dc2c-4251-82c8-3f7ad432245e",
   "metadata": {},
   "source": [
    "## functions to show an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ce28cb-8658-43d8-9fbd-6a0f539d50b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_dataloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(16)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c574b54-b17d-410b-8baa-af5623132981",
   "metadata": {},
   "source": [
    "## initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75869c5f-e161-431b-bbaa-b32602b0391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = 3\n",
    "output_shape = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9eadaa-8496-4876-9cbd-c6acfed3a758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Conv_Net()\n",
    "model = ResNet34(input_channels, output_shape).to(device) #モデルを指定したデバイスに送る\n",
    "#model.to(device) \n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726b3de2-59b9-4aac-9e7c-9b56fdf7dfcd",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d5088985-160b-4dc7-922a-664ef6839017",
   "metadata": {},
   "source": [
    "num_epocs: エポック数\n",
    "losses: エポック毎の損失の値を格納するリスト（学習時）\n",
    "accs: エポック毎のaccuracyの値を格納するリスト（学習時）\n",
    "val_losses: エポック毎の損失の値を格納するリスト（検証時）\n",
    "val_accs: エポック毎のaccuracyの値を格納するリスト（検証時）\n",
    "\n",
    "running_loss: エポック毎の損失の値\n",
    "running_acc: エポック毎のaccuracyの値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5308f3-c7cc-4e98-8134-a01839d3f21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_metric = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc16d4e-2f92-4b1c-849a-fac8212d5ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    print(f'[{epoch+1}, {i+1}] loss: {running_loss/len(dataloader)}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20b0fc6-d6c5-4e41-b39a-d19831260ffb",
   "metadata": {},
   "source": [
    "## save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0814bbd-c4ea-4e36-83a7-f8d9af4ba5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../output/cifar_net.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359130ac-e2ee-4c56-9179-7b1845b455a6",
   "metadata": {},
   "source": [
    "## test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62042730-f82a-4f54-ba4f-9271374a15f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(validation_dataloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "net = Conv_Net()\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "outputs = net(images)\n",
    "\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in validation_dataloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d08eb26-fc18-479a-9f38-5dfbf8e566bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in validation_dataloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea0f216-8cb9-4163-b8d6-378e633151c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
